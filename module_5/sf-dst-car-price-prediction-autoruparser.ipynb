{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Прогнозирование стоимости автомобиля по характеристикам\n\n\nОбразовательная платформа: SkillFactory\n\nСпециализация: Data Science\n\nГруппа: DST-37 и 38\n\nЮнит 6. Проект 5: \"Выбираем автомобиль правильно\"\n\n\n### Задача:\n\n    Создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам для того, чтобы выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены).\n\n### Метрика:\n\n    MAPE (Mean Percentage Absolute Error) - средняя абсолютная ошибка в процентах\n\n### Нужно:\n\n    Составить train датасет - спарсить данные, либо найти готовый\n    Обучить модель\n\n### Плюс:\n\n    Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n    Сгенерировать новые признаки\n    Подгрузить еще больше данных\n    Попробовать подобрать параметры модели\n    Попробовать разные алгоритмы и библиотеки ML\n    Сделать Ансамбль моделей, Blending, Stacking\n\n### Этапы работы:\n\n    Парсинг с авто.ру - Вадим\n    EDA, Feature Engineering - Артём, Вадим, Женя\n    Сравнение одиночных моделей - Артём, Вадим\n    Стекинг - Вадим\n\n#### В данном ноутбуке мы проводим парсинг данных с сайта auto.ru\n\n#### Также в этом проекте мы использовали:\n\nСпарсенный датасет мы взяли у этой команды, потому что парсинг занимал очень много времени: https://www.kaggle.com/juliadeinego/data-car-sales\n\nНоутбук, в котором провели EDA: https://www.kaggle.com/artemskakun/sf-dst-car-price-prediction-datapreprocessing\n\nНоутбук, в котором провели ML: https://www.kaggle.com/artemskakun/sf-dst-car-price-prediction-ml","metadata":{}},{"cell_type":"code","source":"#!pip install -U selenium\n#!pip install beautifulsoup4","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting selenium\n  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n\u001b[K     |████████████████████████████████| 904 kB 5.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from selenium) (1.26.4)\nInstalling collected packages: selenium\nSuccessfully installed selenium-3.141.0\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (4.9.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4) (2.2.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport csv\nimport time\nimport pandas as pd\nimport re\nimport pdb\nfrom selenium import webdriver\n\nBASE_URL = 'https://auto.ru'\nFROM_YEAR = 2000\nMARKS_TO_PARSE = ['SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI',\n                  'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI']","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Функции","metadata":{}},{"cell_type":"code","source":"# функция записи выбранных данных\ndef write_csv(trend, parsing_unixtime, models, prices, years, mileages, bodyTypes, colors, engines,\n              transmissions, drives, wheels, states, owners, ptss):\n\n    lenlist = len(models)\n    i = 0\n\n    with open(f'{PROJECT_PATH}data\\\\{trend}.csv', 'a', encoding=\"utf-8\", newline='') as f:\n        writer = csv.writer(f)\n\n        while i <= (lenlist-1):\n            writer.writerow([trend, parsing_unixtime, models[i], prices[i], years[i], mileages[i], bodyTypes[i],\n                             colors[i], engines[i], transmissions[i], drives[i], wheels[i], states[i], owners[i], ptss[i]])\n            i = i+1\n\n# функция очистки текста от лишних символов\ndef clear_text(elem):\n    if elem:\n        if elem == \"NaN\":\n            return elem\n        return elem.text\\\n            .replace(\"&nbsp;\", \"\")\\\n            .replace(\"₽\", \"\")\\\n            .replace(\"\\xa0\", \"\")\\\n            .replace(\"\\u2009\", \"\")\\\n            .replace(\"/\", \"|\")\n    else:\n        return \"NaN\"\n    return models, prices, years, kms, descs\n\n# функция вычленения текста из линка\ndef get_info_from_link(el, cls):\n    span = get_info_from_span(el, cls)\n    if span:\n        return span.find('a', class_='Link_color_black')\n    return \"NaN\"\n\n# функция вычленения текста из спана\ndef get_info_from_span(el, cls):\n    if el:\n        li = el.find('li', class_=cls)\n        if li:\n            spans = li.find_all('span', class_='CardInfoRow__cell')\n            if len(spans) == 1:\n                return spans[0]\n            elif len(spans) > 1:\n                return spans[1]\n    return \"NaN\"\n\n# функция проходит по странице брэнда, переходит на страницу объявления. получив данные, сохраняет в списках признаков\ndef get_page_data(html):\n    html = browser.page_source\n    soup = BeautifulSoup(html, 'html.parser')\n    car_rows = soup.find_all('div', class_='ListingCars-module__listingItem')\n    print(f'now found {len(car_rows)} on the page')\n    models = []\n    prices = []\n    years = []\n    mileages = []\n    bodyTypes = []\n    colors = []\n    engines = []\n    transmissions = []\n    drives = []\n    wheels = []\n    states = []\n    owners = []\n    ptss = []\n\n    for car in car_rows:\n        info = {}\n        price = 0\n        try:\n            model = car.find('a', class_='ListingItemTitle-module__link')\n            model_full_name = model.text\n            model_url = model['href']\n            # print(model_full_name,model_url)\n            browser.get(model_url)\n            html = browser.page_source\n            price = clear_text(\n                car.find('div', class_='ListingItemPrice-module__content'))\n\n            info = get_model_data(model_url, html)\n        except:\n            print('Ошибка при парсинге', model_full_name, model_url)\n            continue\n\n        # print(info)\n        prices.append(price)\n        models.append(info['model'])\n        years.append(info['year'])\n        mileages.append(info['mileage'])\n        bodyTypes.append(info['bodyType'])\n        colors.append(info['color'])\n        engines.append(info['engine'])\n        transmissions.append(info['transmission'])\n        drives.append(info['drive'])\n        wheels.append(info['wheel'])\n        states.append(info['state'])\n        owners.append(info['owners_count'])\n        ptss.append(info['pts'])\n\n    return models, prices, years, mileages, bodyTypes, colors, engines, \\\n        transmissions, drives, wheels, states, owners, ptss\n\n# функция получает данные со страницы объявления\ndef get_model_data(url, html):\n    soup = BeautifulSoup(html, 'html.parser')\n    cardInfo = soup.find('ul', class_='CardInfo')\n\n    model_links = soup.find_all('a', class_='CardBreadcrumbs__itemText')\n    model = ''\n    if len(model_links) >= 4:\n        model = clear_text(model_links[2])\n        model += '|' + clear_text(model_links[3])\n    elif soup.find('h1', class_='CardHead-module__title'):\n        model = soup.find('h1', class_='CardHead-module__title').text\n    else:\n        print('problem in', model, model_links)\n\n    year = clear_text(get_info_from_link(cardInfo, 'CardInfoRow_year'))\n    if year == \"NaN\":\n        print('Error found on link:', url)\n\n    mileage = clear_text(get_info_from_span(cardInfo, 'CardInfoRow_kmAge'))\n    bodyType = clear_text(get_info_from_link(cardInfo, 'CardInfoRow_bodytype'))\n    color = clear_text(get_info_from_link(cardInfo, 'CardInfoRow_color'))\n    engine = get_info_from_span(cardInfo, 'CardInfoRow_engine')\n    engine_txt = ''\n    if engine.find('div'):\n        engine_txt = clear_text(engine.find('div'))\n    else:\n        engine_txt = clear_text(engine)\n    transmission = clear_text(get_info_from_span(\n        cardInfo, 'CardInfoRow_transmission'))\n    drive = clear_text(get_info_from_span(cardInfo, 'CardInfoRow_drive'))\n    wheel = clear_text(get_info_from_span(cardInfo, 'CardInfoRow_wheel'))\n    state = clear_text(get_info_from_span(cardInfo, 'CardInfoRow_state'))\n    owners_count = clear_text(get_info_from_span(\n        cardInfo, 'CardInfoRow_ownersCount'))\n    pts = clear_text(get_info_from_span(cardInfo, 'CardInfoRow_pts'))\n    time.sleep(0.1)\n\n    return {'model': model, 'year': year, 'mileage': mileage, 'bodyType': bodyType, 'color': color, 'engine': engine_txt, 'transmission': transmission, 'drive': drive, 'wheel': wheel, 'state': state, 'owners_count': owners_count, 'pts': pts}\n\n# функция собирает все имена брэндов\ndef get_marks(html):\n    soup = BeautifulSoup(html, 'html.parser')\n    marks = soup.find_all('a', class_='IndexMarks__item', href=True)\n    mark_names = []\n    for mark in marks:\n        name = mark.find('div', class_='IndexMarks__item-name').text\n        url = mark['href'].replace('all', 'used')\n        mark_names.append({'name': name, 'url': url})\n\n    return mark_names\n\n# функция получает список страниц брэнда и проходит по ним\ndef get_mark_data(browser, mark, year_from, page_from=1, already_found=0):\n    # enter into specific mark page\n    url = mark['url']\n    url_gen = url + '?year_from=' + str(year_from)\n    mark_name = mark['name']\n\n    word = 'cars/'\n    start = url.index(word, 0) + len(word)\n    end = url.index('/', start)\n    trend = url[start:end]\n    parsing_unixtime = int(time.time())\n\n    print(url_gen)\n    browser.get(url_gen)\n    html = browser.page_source\n    soup = BeautifulSoup(html, 'html.parser')\n\n    # get car's count\n    pattern = re.compile('\\d+')\n    count_text = clear_text(\n        soup.find('span', class_='ButtonWithLoader__content'))\n    count_total = 0\n    res = pattern.findall(count_text)\n    if len(res) > 0:\n        count_total = int(res[0])\n    print('count_total=', count_total)\n\n    found_cars = already_found\n    page = page_from\n    while found_cars < count_total:\n        # prepare next page url\n        page_url = url_gen + '&page=' + str(page)\n        print(page_url)\n        page += 1\n        # retrieve nex page\n        browser.get(page_url)\n        # retrieve data of cars on the page\n        models, prices, years, mileages, bodyTypes, colors, engines, \\\n            transmissions, drives, wheels, states, owners, ptss = get_page_data(\n                browser)\n        # write to appropriate file with name of mark\n        write_csv(trend, parsing_unixtime, models, prices, years, mileages, bodyTypes, colors, engines,\n                  transmissions, drives, wheels, states, owners, ptss)\n        # add found cars\n        found_cars += len(models)\n\n        # wait 1 second before retrieve next page\n        time.sleep(1)\n\n    print(f'finished download {mark_name} - {found_cars} rows')\n\n# функция делает логин на auto.ru и запускает процесс получения данных\ndef do_login_and_get_marks():\n    browser = webdriver.Firefox(executable_path=PROJECT_PATH+'geckodriver.exe')\n    browser.get(BASE_URL)\n    html = browser.page_source\n\n    # do confirmation\n    if len(browser.find_elements_by_id('confirm-button')) > 0:  # pay attention: find_element*s*\n        # pay attention: find_element\n        browser.find_element_by_id('confirm-button').click()\n        print('login')\n\n    # get marks\n    browser.get(BASE_URL)\n    # open all models\n    # pay attention: find_element*s*\n    if len(browser.find_elements_by_class_name('IndexMarks__show-all')) > 0:\n        browser.find_element_by_class_name(\n            'IndexMarks__show-all').click()  # pay attention: find_element\n\n    html = browser.page_source\n    marks = get_marks(html)\n    return browser, marks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Логин в AUTO.RU ","metadata":{}},{"cell_type":"code","source":"# browser, marks = do_login_and_get_marks()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Парсинг с AUTO.RU","metadata":{}},{"cell_type":"code","source":"# \n# for mark in marks:\n#     if mark['name'].upper() in MARKS_TO_PARSE:\n#         print(mark)\n#         get_mark_data(browser, mark, FROM_YEAR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}